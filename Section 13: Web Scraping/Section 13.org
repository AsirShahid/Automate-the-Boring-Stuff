#+TITLE: Section 13
#+SUBTITLE: Web Scraping
#+AUTHOR: Mohammed Asir Shahid
#+EMAIL: MohammedShahid@protonmail.com
#+DATE: 2021-08-05

* The webbrowser Module

#+begin_src python :results output :exports both :session *my-python*

import webbrowser

webbrowser.open("https://asir.dev")

#+end_src

#+RESULTS:

Let's create a program that can open a given address on maps.

#+begin_src python :results output :exports both :session *my-python* :tangle mapit.py

import webbrowser, sys, pyperclip

sys.argv # ["mapit.py", "870", "Valencia", "St."]

# Check if command line arguments were passed

if len(sys.argv) > 1:
    # ["mapit.py", "870", "Valencia", "St."] -> 870 Valencia St.
    address=" ".join(sys.argv[1:])
else:
    address=pyperclip.paste()

webbrowser.open("https://www.google.com/maps/place/%s" % (address))

#+end_src

* Downloading from the Web with the Requests Module

The requests module lets you easily download files from the web without having to worry about complicated network issues. The requests module is a third party module which we'll need to install on our own.

#+begin_src bash
pip install requests
#+end_src

#+RESULTS:
| Defaulting  | to      | user       | installation                            | because | normal                           | site-packages | is        | not      | writeable |
| Requirement | already | satisfied: | requests                                | in      | /usr/lib/python3.9/site-packages | (2.24.0)      |           |          |           |
| Requirement | already | satisfied: | chardet<4,>=3.0.2                       | in      | /usr/lib/python3.9/site-packages | (from         | requests) | (3.0.4)  |           |
| Requirement | already | satisfied: | idna<3,>=2.5                            | in      | /usr/lib/python3.9/site-packages | (from         | requests) | (2.10)   |           |
| Requirement | already | satisfied: | urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 | in      | /usr/lib/python3.9/site-packages | (from         | requests) | (1.25.8) |           |

We can pass a URL to the requests.get() function in order to get the file. We can check the status code to see if it downloaded properly, if so then we'll get the status code 200. We can print out the file using .text. We can also see if there is an issue by calling the raise_for_status() method which will raise an error if we ran into any problems.

#+begin_src python :results output :exports both

import requests

res=requests.get("http://automatetheboringstuff.com/files/rj.txt")

print(res.status_code)

print(len(res.text))
print(res.text[:500])

print(res.raise_for_status())

badRes=requests.get("http://automatetheboringstuff.com/files/rjuliet.txt")

print(badRes.raise_for_status())

#+end_src

#+RESULTS:

** Write-binary mode: open(filename, "wb")

We can save a web page to a file using the open function. However, we must do somethings differently.

#+begin_src python :results output :exports both

import requests

res=requests.get("http://automatetheboringstuff.com/files/rj.txt")
playFile=open("RomeoAndJuliet.txt","wb")

for chunk in res.iter_content(100000):
    playFile.write(chunk)

playFile.close()

#+end_src

#+RESULTS:

Request module functions can be useful, but they are somewhat limited. You can only use it when you have the exact URL that you need to download. Selenium lets your Python scripts control the web browser directly.
